{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris:\n",
    "    def __init__(self,input_size,hidden_size,output_size,learning_rate):\n",
    "        self.input_size=input_size\n",
    "        self.output_size=output_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.learning_rate=learning_rate\n",
    "        #Initialize weights and bias\n",
    "        self.Vij=np.random.uniform(-0.5,0.5,(self.input_size,self.hidden_size))\n",
    "        self.Wjk=np.random.uniform(-0.5,0.5,(self.hidden_size,self.output_size))\n",
    "        self.Vbj=np.random.uniform(-0.5,0.5,(1,self.hidden_size))\n",
    "        self.Wbk=np.random.uniform(-0.5,0.5,(1,self.output_size))\n",
    "\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x*(1-x)\n",
    "    def forward_propogation(self,x):\n",
    "            self.hidden_input=np.dot(x,self.Vij)+self.Vbj\n",
    "            self.hidden_output=self.sigmoid(self.hidden_input)\n",
    "            self.output_input=np.dot(self.hidden_output,self.Wjk) + self.Wbk\n",
    "            self.output_final=self.sigmoid(self.output_input)\n",
    "            return self.output_final\n",
    "    def backword_propogation(self,x,y,output):\n",
    "        error=y-output\n",
    "        #Weight correction in weights\n",
    "        delta_K=error * self.sigmoid_derivative(output)#Output layer error\n",
    "        delta_in=delta_K.dot(self.Wjk.T)#Hidden Unit error\n",
    "        delta_J=delta_in * self.sigmoid_derivative(self.hidden_output)#Hidden Layer error\n",
    "\n",
    "\n",
    "        # Weigth adjustent in  Weight vector between Output and hidden layer\n",
    "        self.Wjk+=self.hidden_output.T.dot(delta_K) * self.learning_rate\n",
    "\n",
    "        #Change in bias between output and hidden layer\n",
    "        self.Wbk+=np.sum(delta_K)*self.learning_rate\n",
    "        \n",
    "        # Weigth adjustent in  Weight vector between input and hidden layer\n",
    "        self.Vij+=x.T.dot(delta_J) * self.learning_rate\n",
    "\n",
    "        #Change in bias between input and hidden layer \n",
    "        self.Vbj+=np.sum(delta_J)*self.learning_rate\n",
    "    def train_model(self,x,y,epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output=self.forward_propogation((x))\n",
    "            self.backword_propogation(x,y,output)\n",
    "            if epoch % 1000 ==0 :\n",
    "                print(f'Epoch{epoch}:Error{np.mean(np.abs(y-output))}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (150, 1), indices imply (150, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m df1\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m.\u001b[39mdata, columns\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mfeature_names)\n\u001b[0;32m      3\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m----> 4\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m.\u001b[39mtarget, columns\u001b[38;5;241m=\u001b[39m[data\u001b[38;5;241m.\u001b[39mtarget_names])\n\u001b[0;32m      5\u001b[0m df2\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    771\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    772\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    773\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    779\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    780\u001b[0m         )\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 782\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    783\u001b[0m             data,\n\u001b[0;32m    784\u001b[0m             index,\n\u001b[0;32m    785\u001b[0m             columns,\n\u001b[0;32m    786\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    787\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    788\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    789\u001b[0m         )\n\u001b[0;32m    791\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (150, 1), indices imply (150, 3)"
     ]
    }
   ],
   "source": [
    "data=datasets.load_iris()\n",
    "df1= pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df1.head()\n",
    "df2 = pd.DataFrame(data.target, columns=[data.target_names])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        1\n",
       "1           4.9          3.0           1.4          0.2        1\n",
       "2           4.7          3.2           1.3          0.2        1\n",
       "3           4.6          3.1           1.5          0.2        1\n",
       "4           5.0          3.6           1.4          0.2        1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['species'] = df['species'].replace({'Iris-setosa': 1, 'Iris-virginica': 0, 'Iris-versicolor': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([df['sepal_length'], df['sepal_width'], df['petal_length'], df['petal_width']]).T\n",
    "Y = np.array(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=30)\n",
    "\n",
    "# One-hot encode target labels for training\n",
    "encoder = OneHotEncoder(categories='auto')\n",
    "y_train_onehot = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_size = 8\n",
    "output_size = y_train_onehot.shape[1]\n",
    "learning_rate = 0.1\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0:Error0.5378261250578386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1000:Error0.23190256064966283\n",
      "Epoch2000:Error0.22954849644253525\n",
      "Epoch3000:Error0.2292588923534707\n",
      "Epoch4000:Error0.22962003343145462\n",
      "Epoch5000:Error0.2302605311741501\n",
      "Epoch6000:Error0.2294295772560626\n",
      "Epoch7000:Error0.22910192341510568\n",
      "Epoch8000:Error0.2289379240037134\n",
      "Epoch9000:Error0.2284718726469615\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "obj_ANN = Iris(input_size, hidden_size, output_size, learning_rate)\n",
    "obj_ANN.train_model(X_train, y_train_onehot, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.03333333333333333\n",
      "'Iris-Versicolor\n",
      "'Iris-Versicolor\n",
      "'Iris-Versicolor\n",
      "Iris-setosa\n",
      "Iris -Virginica\n",
      "Iris -Virginica\n",
      "Iris-setosa\n",
      "Iris-setosa\n",
      "Iris -Virginica\n",
      "Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "output = obj_ANN.forward_propogation(X_test)\n",
    "predicted_labels = np.argmax(output, axis=1)\n",
    "accuracy = np.mean(predicted_labels == y_test.flatten())\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
